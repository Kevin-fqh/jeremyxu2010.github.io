<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>tensorflow学习笔记_02 - jeremy的技术点滴</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="Jeremy Xu" />
  <meta name="description" content="上一篇笔记采用一个线性关系的神经层处理了MNIST的训练数据，最后得到一个准确率一般的神经网络。但其实对于这种图像识别的场景，tensorf" />




<meta name="google-site-verification" content="Ol4gI1XKZ2qsa-efwwJvaGeDyXb91RL-pZBv-3uyY-A" />


<meta name="generator" content="Hugo " />


<link rel="canonical" href="https://jeremyxu2010.github.io/2017/03/tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_02/" />

<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">







<link href="/dist/even.min.css?v=3.1.1" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">



<link rel="stylesheet" href="/css/mathjax.css">


<meta property="og:title" content="tensorflow学习笔记_02" />
<meta property="og:description" content="上一篇笔记采用一个线性关系的神经层处理了MNIST的训练数据，最后得到一个准确率一般的神经网络。但其实对于这种图像识别的场景，tensorf" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://jeremyxu2010.github.io/2017/03/tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_02/" />
<meta property="article:published_time" content="2017-03-02T18:20:00+08:00" />
<meta property="article:modified_time" content="2017-03-02T18:20:00+08:00" />
<meta itemprop="name" content="tensorflow学习笔记_02">
<meta itemprop="description" content="上一篇笔记采用一个线性关系的神经层处理了MNIST的训练数据，最后得到一个准确率一般的神经网络。但其实对于这种图像识别的场景，tensorf">
<meta itemprop="datePublished" content="2017-03-02T18:20:00&#43;08:00" />
<meta itemprop="dateModified" content="2017-03-02T18:20:00&#43;08:00" />
<meta itemprop="wordCount" content="1164">



<meta itemprop="keywords" content="tensorflow,python," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="tensorflow学习笔记_02"/>
<meta name="twitter:description" content="上一篇笔记采用一个线性关系的神经层处理了MNIST的训练数据，最后得到一个准确率一般的神经网络。但其实对于这种图像识别的场景，tensorf"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">jeremy的技术点滴</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/search/">
        <li class="mobile-menu-item">Search</li>
      </a>
  </ul>
</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">jeremy的技术点滴</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/search/">Search</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">tensorflow学习笔记_02</h1>

      <div class="post-meta">
        <span class="post-time"> 2017-03-02 </span>
        <div class="post-category">
            
              <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"> 机器学习 </a>
            
          </div>
        <span class="more-meta"> 约 1164 字 </span>
        <span class="more-meta"> 预计阅读 3 分钟 </span>
        
      </div>
    </header>

    
    
<div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#heading">卷积与池化</a></li>
    <li><a href="#heading-1">示例程序</a></li>
    <li><a href="#heading-2">总结</a></li>
    <li><a href="#heading-3">参考</a></li>
  </ul>
</nav>
  </div>
</div>

    
    <div class="post-content">
      <p>上一篇笔记采用一个线性关系的神经层处理了MNIST的训练数据，最后得到一个准确率一般的神经网络。但其实对于这种图像识别的场景，tensorflow里还可以使用卷积神经网络技术进行准确率更高的机器学习。</p>
<h2 id="heading">卷积与池化</h2>
<p><code>卷积</code>是一个数学上的概念，简单说就是拿<code>卷积核</code>从原始图像里提取特征映射，将一张图片转化为多张包含特征映射的图片。理解<code>卷积</code>可以读一下<a href="https://www.zhihu.com/question/22298352">这篇帖子</a>，里面除了很抽象的数学定义外，还有一些便于理解的示例。
<code>池化</code>主要用来浓缩卷积层的输出结果并创建一个压缩版本的信息并输出。</p>
<h2 id="heading-1">示例程序</h2>
<p>学习卷积神经网络，我也参照官方的代码写了个小例子，如下。</p>
<p><code>demo2.py</code></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> tensorflow <span style="color:#f92672">as</span> tf
<span style="color:#75715e"># 下载mnist并加载MNIST的训练数据</span>
<span style="color:#f92672">import</span> tensorflow.examples.tutorials.mnist.input_data <span style="color:#f92672">as</span> input_data
mnist <span style="color:#f92672">=</span> input_data<span style="color:#f92672">.</span>read_data_sets(<span style="color:#e6db74"></span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">MNIST_data/</span><span style="color:#e6db74">&#34;</span>, one_hot<span style="color:#f92672">=</span>True)
<span style="color:#75715e"># 定义两个方法，用以产生带稍许噪音的权值与偏值</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">weight_variable</span>(shape):
    initial <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>truncated_normal(shape, stddev<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>)
    <span style="color:#66d9ef">return</span> tf<span style="color:#f92672">.</span>Variable(initial)
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">bias_variable</span>(shape):
    initial <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>constant(<span style="color:#ae81ff">0.1</span>, shape<span style="color:#f92672">=</span>shape)
    <span style="color:#66d9ef">return</span> tf<span style="color:#f92672">.</span>Variable(initial)
<span style="color:#75715e"># 定义工具方法，用以创建隐藏层</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">add_layer</span>(inputs, Weights, biases, activation_function<span style="color:#f92672">=</span>None):
    <span style="color:#75715e"># add one more layer and return the output of this layer</span>
    Wx_plus_b <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>add(tf<span style="color:#f92672">.</span>matmul(inputs, Weights), biases)
    <span style="color:#66d9ef">if</span> activation_function <span style="color:#f92672">is</span> None:
        outputs <span style="color:#f92672">=</span> Wx_plus_b
    <span style="color:#66d9ef">else</span>:
        outputs <span style="color:#f92672">=</span> activation_function(Wx_plus_b, )
    <span style="color:#66d9ef">return</span> outputs
<span style="color:#75715e"># 定义工具方法，创建卷积层</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">conv2d</span>(x, W):
    <span style="color:#66d9ef">return</span> tf<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>conv2d(x, W, strides<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], padding<span style="color:#f92672">=</span><span style="color:#e6db74"></span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">SAME</span><span style="color:#e6db74">&#39;</span>)
<span style="color:#75715e"># 定义工具方法，创建池化层</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">max_pool_2x2</span>(x):
    <span style="color:#66d9ef">return</span> tf<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>max_pool(x, ksize<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1</span>], strides<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1</span>], padding<span style="color:#f92672">=</span><span style="color:#e6db74"></span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">SAME</span><span style="color:#e6db74">&#39;</span>)
<span style="color:#75715e"># 定义两个外部传入的张量</span>
x <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>placeholder(tf<span style="color:#f92672">.</span>float32, [None, <span style="color:#ae81ff">784</span>])
y <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>placeholder(tf<span style="color:#f92672">.</span>float32, [None, <span style="color:#ae81ff">10</span>])
<span style="color:#75715e"># drop层使用到的保留比率</span>
keep_prob <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>placeholder(tf<span style="color:#f92672">.</span>float32)
<span style="color:#75715e"># 将原始二维数据reshape为四维数据</span>
x_image <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>reshape(x, [<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">28</span>, <span style="color:#ae81ff">28</span>, <span style="color:#ae81ff">1</span>]) <span style="color:#75715e"># (samples, 28, 28, 1)</span>
<span style="color:#75715e"># 第一层卷积层及池化层</span>
W_conv1 <span style="color:#f92672">=</span> weight_variable([<span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">32</span>])
b_conv1 <span style="color:#f92672">=</span> bias_variable([<span style="color:#ae81ff">32</span>])
h_conv1 <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>relu(conv2d(x_image, W_conv1) <span style="color:#f92672">+</span> b_conv1) <span style="color:#75715e"># (samples, 28, 28, 32)</span>
h_pool1 <span style="color:#f92672">=</span> max_pool_2x2(h_conv1) <span style="color:#75715e"># (samples, 14, 14, 32)</span>
<span style="color:#75715e"># 第二层卷积及池化层</span>
W_conv2 <span style="color:#f92672">=</span> weight_variable([<span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">32</span>, <span style="color:#ae81ff">64</span>])
b_conv2 <span style="color:#f92672">=</span> bias_variable([<span style="color:#ae81ff">64</span>])
h_conv2 <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>relu(conv2d(h_pool1, W_conv2) <span style="color:#f92672">+</span> b_conv2) <span style="color:#75715e"># (samples, 14, 14, 64)</span>
h_pool2 <span style="color:#f92672">=</span> max_pool_2x2(h_conv2) <span style="color:#75715e"># (samples, 7, 7, 64)</span>
<span style="color:#75715e"># 将四维的输出reshape为二维数据</span>
h_pool2_flat <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>reshape(h_pool2, [<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">7</span><span style="color:#f92672">*</span><span style="color:#ae81ff">7</span><span style="color:#f92672">*</span><span style="color:#ae81ff">64</span>]) <span style="color:#75715e"># (samples, 7*7*64)</span>
<span style="color:#75715e"># 添加一个隐藏层</span>
W_fc1 <span style="color:#f92672">=</span> weight_variable([<span style="color:#ae81ff">7</span><span style="color:#f92672">*</span><span style="color:#ae81ff">7</span><span style="color:#f92672">*</span><span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">1024</span>])
b_fc1 <span style="color:#f92672">=</span> bias_variable([<span style="color:#ae81ff">1024</span>])
h_fc1 <span style="color:#f92672">=</span> add_layer(h_pool2_flat, W_fc1, b_fc1, tf<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>relu) <span style="color:#75715e"># (samples, 1024)</span>
<span style="color:#75715e"># 添加一个按比率随机drop层</span>
h_fc1_drop <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>dropout(h_fc1, keep_prob) <span style="color:#75715e"># (samples, 1024)</span>
<span style="color:#75715e"># 使用softmax回归模型计算出预测的y，这个是用来分类处理的</span>
W_fc2 <span style="color:#f92672">=</span> weight_variable([<span style="color:#ae81ff">1024</span>, <span style="color:#ae81ff">10</span>])
b_fc2 <span style="color:#f92672">=</span> bias_variable([<span style="color:#ae81ff">10</span>])
prediction_y <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>softmax(tf<span style="color:#f92672">.</span>add(tf<span style="color:#f92672">.</span>matmul(h_fc1_drop, W_fc2), b_fc2)) <span style="color:#75715e"># (samples, 10)</span>
<span style="color:#75715e"># 使用交叉熵计算预测的y与实际的y的损失</span>
loss <span style="color:#f92672">=</span> <span style="color:#f92672">-</span>tf<span style="color:#f92672">.</span>reduce_sum(y<span style="color:#f92672">*</span>tf<span style="color:#f92672">.</span>log(prediction_y))
<span style="color:#75715e"># 使用AdamOptimizer以0.0001的学习速率最小化交叉熵</span>
train_step <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>train<span style="color:#f92672">.</span>AdamOptimizer(<span style="color:#ae81ff">1e-4</span>)<span style="color:#f92672">.</span>minimize(loss)
<span style="color:#75715e"># 计算预测的y与实际的y是否匹配，返回为[True, False, True, True...]</span>
correct_prediction <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>equal(tf<span style="color:#f92672">.</span>argmax(prediction_y, <span style="color:#ae81ff">1</span>), tf<span style="color:#f92672">.</span>argmax(y, <span style="color:#ae81ff">1</span>))
<span style="color:#75715e"># 计算上一步计算出来的张量的平均值</span>
accuracy <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>reduce_mean(tf<span style="color:#f92672">.</span>cast(correct_prediction, <span style="color:#e6db74"></span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">float</span><span style="color:#e6db74">&#34;</span>))

<span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>Session() <span style="color:#66d9ef">as</span> sess:
    <span style="color:#75715e"># 初始化所有变量</span>
    sess<span style="color:#f92672">.</span>run(tf<span style="color:#f92672">.</span>global_variables_initializer())
    <span style="color:#75715e"># 循环训练1000次，每次从MNIST的训练数据中随机抽出100条进行训练</span>
    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1000</span>):
        batch_xs, batch_ys <span style="color:#f92672">=</span> mnist<span style="color:#f92672">.</span>train<span style="color:#f92672">.</span>next_batch(<span style="color:#ae81ff">100</span>)
        sess<span style="color:#f92672">.</span>run(train_step, feed_dict<span style="color:#f92672">=</span>{x: batch_xs, y: batch_ys, keep_prob: <span style="color:#ae81ff">0.5</span>})
        <span style="color:#66d9ef">if</span> i <span style="color:#f92672">%</span> <span style="color:#ae81ff">10</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>:
            <span style="color:#75715e"># 使用MNIST的测试数据计算模型的准确率</span>
            batch_xs, batch_ys <span style="color:#f92672">=</span> mnist<span style="color:#f92672">.</span>test<span style="color:#f92672">.</span>next_batch(<span style="color:#ae81ff">100</span>)
            <span style="color:#66d9ef">print</span>(sess<span style="color:#f92672">.</span>run(accuracy, \
                feed_dict<span style="color:#f92672">=</span>{x: batch_xs, y: batch_ys, keep_prob: <span style="color:#ae81ff">0.5</span>}))

</code></pre></div><p>代码注释得很清楚了，为了便于理解，多个层之间转换时，我也将张量的shape标示出来了。</p>
<h2 id="heading-2">总结</h2>
<p>本篇作为tensorflow入门的一个较复杂的例子，其中涉及了较多数学知识，理解起来还是挺困难的。后面我会尝试用tensorboard等工具将神经网络以可视化的方式呈现出来，这样可能容易理解一点。看到一句话，原以为深度学习工程师很高大上，原来大家都是这么干活的。</p>
<blockquote>
<p>话说，深度学习工程师50%的时间在调参数，49%的时间在对抗过/欠拟合，剩下1%时间在修改网上down下来的程序。</p>
</blockquote>
<h2 id="heading-3">参考</h2>
<p><code>http://wiki.jikexueyuan.com/project/tensorflow-zh/tutorials/deep_cnn.html</code>
<code>http://www.jianshu.com/p/3b611043cbae</code>
<code>https://www.zhihu.com/question/22298352?rf=21686447</code>
<code>https://www.zhihu.com/question/38098038</code></p>

    </div>

    
    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">Jeremy Xu</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">2017-03-02</span>
  </p>
  
  <p class="copyright-item">
    <span class="item-title">许可协议</span>
    <span class="item-content">&copy; Copyright 2020 Jeremy Xu</span>
  </p>
</div>

    
    
<div class="post-reward">
  <input type="checkbox" name="reward" id="reward" hidden />
  <label class="reward-button" for="reward">赞赏支持</label>
  <div class="qr-code">
    
    
      <label class="qr-code-image" for="reward">
        <img class="image" src="/wechat-qr-code.png">
        <span>微信打赏</span>
      </label>
    
      <label class="qr-code-image" for="reward">
        <img class="image" src="/alipay-qr-code.png">
        <span>支付宝打赏</span>
      </label>
  </div>
</div>

    <footer class="post-footer">
      <div class="post-tags">
          
          <a href="/tags/tensorflow/">tensorflow</a>
          
          <a href="/tags/python/">python</a>
          
        </div>

      
      <nav class="post-nav">
        
          <a class="prev" href="/2017/03/mybatis-generator%E4%BD%BF%E7%94%A8%E5%A4%87%E5%BF%98/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">mybatis-generator使用备忘</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        
          <a class="next" href="/2017/02/tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_01/">
            <span class="next-text nav-default">tensorflow学习笔记_01</span>
            <span class="prev-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        


<div id="utter-container"></div>
<script src="https://utteranc.es/client.js" repo='jeremyxu2010/blog_comment'
  issue-term="title" theme='github-light' crossorigin="anonymous" async>
  </script>
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:jeremyxu2010@gmail.com" class="iconfont icon-email" title="email"></a>
      <a href="https://plus.google.com/u/0/103057094241630654183" class="iconfont icon-google" title="google"></a>
      <a href="https://github.com/jeremyxu2010" class="iconfont icon-github" title="github"></a>
  <a href="https://jeremyxu2010.github.io/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    
      2016 - 
    2020
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">&copy; Copyright 2019 Jeremy Xu</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
<script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>
<script type="text/javascript" src="/dist/even.min.js?v=3.1.1"></script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      displayMath: [['$$','$$'], ['\[\[','\]\]']],
      processEscapes: true,
      processEnvironments: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      TeX: { equationNumbers: { autoNumber: "AMS" },
           extensions: ["AMSmath.js", "AMSsymbols.js"] }
    }
  });
  
  MathJax.Hub.Queue(function() {
      
      
      
      var all = MathJax.Hub.getAllJax(), i;
      for(i = 0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
  </script>








<script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.0/fuse.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js"></script>
<script src="https://jeremyxu2010.github.io/js/search.js"></script>


</body>
</html>
